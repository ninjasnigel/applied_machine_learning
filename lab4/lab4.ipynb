{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA4: Implementing linear classifiers\n",
    "### Authors: David Laessker, Peter Fagrell \n",
    "\n",
    "\n",
    "\n",
    "## Exercise Question\n",
    "\n",
    "Since the perceptron is a linnear classifier it can only classify data that is linearly seperable. This means that it can only classify data that can be seperated by a line. We can represent this very arcaheicly by the following:\n",
    "\n",
    "Trainig data 1 would look like this \n",
    "\n",
    "x|x\n",
    "-|-\n",
    "x|o\n",
    "\n",
    "and training data 2 would look like this\n",
    "\n",
    "o|x\n",
    "-|-\n",
    "x|o\n",
    "\n",
    "The top two boxes are Gothenburg/Sydney bottom two are Paris,  the right boxes are July and the left boxes are December.\n",
    "\n",
    "\n",
    "As we can see we can easily draw a line that separates the two classes in example 1 but not in example 2. This means that the perceptron can only classify example 1 and not example 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "## Implementing the SVC\n",
    "\n",
    "### The following table shows the accuracy achived with the different classifiers\n",
    "\n",
    "| Classifier | Accuracy |\n",
    "| --- | --- |\n",
    "| PegasosSVC | 0.8431 |\n",
    "| PegasosLREG | 0.8309 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our implemetation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for lab 4\n",
    "import numpy as np\n",
    "from aml_perceptron import LinearClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The _PegasosSVC_ was implemented with by translating the pseudocode from the document _'Clarification of the pseudocode in the Pegasos paper'_ with the help of the clarification in said document. The algorithm was run with several different combinations of parameters before settling on the following:\n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| lambda_reg | 0.01 |\n",
    "|n_iter | 100 000 |\n",
    "\n",
    "### The code cell below shows the implementation of the PegasosSVC algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PegasosSVC(LinearClassifier):\n",
    "    \"\"\"\n",
    "    Implementation of the Pegasos algorithm for SVCs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_reg=0.1, n_iter=1000000):\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        # Preprocess the data\n",
    "        self.find_classes(Y)\n",
    "        Y_encoded = self.encode_outputs(Y)\n",
    "\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = X.toarray()\n",
    "\n",
    "        # Initialize the weights\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.lambda_reg = 1/n_features\n",
    "\n",
    "        # Pegasos algorithm implemented\n",
    "        # like the peudocode in the paper\n",
    "        for t in range(1, self.n_iter):\n",
    "            rand = np.random.randint(0, len(X))\n",
    "            x, y = X[rand], Y_encoded[rand]\n",
    "\n",
    "            n = 1/(self.lambda_reg*t)\n",
    "\n",
    "            score = x.dot(self.w)\n",
    "\n",
    "            if y*score <= 1:\n",
    "                self.w = (1 - n*self.lambda_reg) * self.w + n*y*x\n",
    "            else:\n",
    "                self.w = (1 - n*self.lambda_reg) * self.w\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following two code cells is doc_classification.py that was provided by the course. It was modified to fit the _PegasosSVC_ algorithm instead of perceptron as it was orignally. We split it up and simplified it to make it easier to understand and to make it easier to implement the _PegasosSVC_ and _PegasosLREG_ algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads the corpus, returns a list of documents, and a list\n",
    "# of their corresponding polarity labels.\n",
    "\n",
    "\n",
    "def read_data(corpus_file):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, y, _, x = line.split(maxsplit=3)\n",
    "            X.append(x.strip())\n",
    "            Y.append(y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When we run the code cell below it will print the **accuracy** of the _PegasosSVC_ algorithm.\n",
    "\n",
    "## Accuracy: 0.8431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 10.66 sec.\n",
      "Accuracy: 0.8431.\n"
     ]
    }
   ],
   "source": [
    "# Read all the documents.\n",
    "X, Y = read_data(\n",
    "    'data/all_sentiment_shuffled.txt')\n",
    "# Split into training and test parts.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                random_state=69)\n",
    "\n",
    "# Set up the preprocessing steps and the classifier.\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    SelectKBest(k=1000),\n",
    "    Normalizer(),\n",
    "    # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "    PegasosSVC()\n",
    ")\n",
    "\n",
    "# Train the classifier.\n",
    "t0 = time.time()\n",
    "pipeline.fit(Xtrain, Ytrain)\n",
    "t1 = time.time()\n",
    "print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "# Evaluate on the test set.\n",
    "Yguess = pipeline.predict(Xtest)\n",
    "print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PegsosLREG is the \n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| lambda_reg | 0.1 |\n",
    "|n_iter | 100 000 |\n",
    "\n",
    "### The code cell below shows the implementation of the PegasosLREG algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PegasosLREG(LinearClassifier):\n",
    "    \"\"\"\n",
    "    Implementation of the Pegasos algorithm for logistic regression.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_reg=0.1, n_iter=100000):\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        # Preprocess the data\n",
    "        self.find_classes(Y)\n",
    "        Y_encoded = self.encode_outputs(Y)\n",
    "\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = X.toarray()\n",
    "\n",
    "        # Initialize the weights\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.lambda_reg = 1/n_features\n",
    "\n",
    "        # Pegasos algorithm implemented with logistic regression\n",
    "        for t in range(1, self.n_iter):\n",
    "            rand = np.random.randint(0, len(X))\n",
    "            x, y = X[rand], Y_encoded[rand]\n",
    "\n",
    "            n = 1/(self.lambda_reg*t)\n",
    "\n",
    "            score = x.dot(self.w)\n",
    "            gradient = -y * x * (1 - 1/(1 + np.exp(-y * score)))\n",
    "\n",
    "            self.w = (1 - n * self.lambda_reg) * self.w - n * gradient\n",
    "            self.w *= min(1, 1 / (np.sqrt(self.lambda_reg)\n",
    "                          * np.linalg.norm(self.w)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PegasosLR(LinearClassifier):\n",
    "    \"\"\"\n",
    "    A straightforward implementation of the pegasos learning algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_iter=20, reg_lambda=0.001, print_loss=True):\n",
    "        \"\"\"\n",
    "        The constructor can optionally take the parameters\n",
    "        - n_iter the number of times to iterate through the training set\n",
    "        - reg_lambda the regularization parameter\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_iter = int(n_iter)\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.print_loss = print_loss\n",
    "\n",
    "        # Initialize the array for losses\n",
    "        self.losses = []\n",
    "\n",
    "        # to avoid warnings about using non-defined attributes\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Train a linear classifier using the pegasos learning algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        # First determine which output class will be associated with positive\n",
    "        # and negative scores, respectively.\n",
    "        self.find_classes(Y)\n",
    "\n",
    "        # Convert all outputs to +1 (for the positive class) or -1 (negative).\n",
    "        Ye = self.encode_outputs(Y)\n",
    "\n",
    "        # If necessary, convert the sparse matrix returned by a vectorizer\n",
    "        # into a normal NumPy matrix.\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = X.toarray()\n",
    "\n",
    "        # Initialize the weight vector to all zeros.\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)\n",
    "\n",
    "        # Pegasos algorithm:\n",
    "        for i in range(self.n_iter):\n",
    "            t = 1\n",
    "\n",
    "            for x, y in zip(X, Ye):\n",
    "\n",
    "                t += 1\n",
    "\n",
    "                # calculate the learning rate, eta\n",
    "                eta = 1 / (self.reg_lambda * t)\n",
    "\n",
    "                # Compute the output score for this instance.\n",
    "                score = x.dot(self.w)\n",
    "\n",
    "                self.losses.append(np.log(1 + np.exp(-y * score)))\n",
    "\n",
    "                # Update the weights by the log loss algorithm\n",
    "                loss_gradient = y / (1 + np.exp(y * score))\n",
    "                self.w = (1 - eta * self.reg_lambda) * \\\n",
    "                    self.w + loss_gradient * eta * x\n",
    "\n",
    "            # if i % 2 == 0 and self.print_loss:\n",
    "            #     avg_loss = sum(self.losses) / len(self.losses)\n",
    "            #     print(f\"Iteration {i}, average loss: {round(avg_loss, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 2.69 sec.\n",
      "Accuracy: 0.8275.\n"
     ]
    }
   ],
   "source": [
    "# Read all the documents.\n",
    "X, Y = read_data(\n",
    "    'data/all_sentiment_shuffled.txt')\n",
    "# Split into training and test parts.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                random_state=69)\n",
    "\n",
    "# Set up the preprocessing steps and the classifier.\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    SelectKBest(k=1000),\n",
    "    Normalizer(),\n",
    "    # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "    PegasosLR()\n",
    ")\n",
    "\n",
    "# Train the classifier.\n",
    "t0 = time.time()\n",
    "pipeline.fit(Xtrain, Ytrain)\n",
    "t1 = time.time()\n",
    "print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "# Evaluate on the test set.\n",
    "Yguess = pipeline.predict(Xtest)\n",
    "print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
