{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA4: Implementing linear classifiers\n",
    "### Authors: David Laessker, Peter Fagrell\n",
    "\n",
    "### !!We added showing of our experimentation with different paramters and made the code runnable in the notebook.\n",
    "\n",
    "## Exercise Question\n",
    "\n",
    "Since the perceptron is a linnear classifier it can only classify data that is linearly seperable. This means that it can only classify data that can be seperated by a line. We can represent this very arcaheicly by the following:\n",
    "\n",
    "Trainig data 1 would look like this \n",
    "\n",
    "x|x\n",
    "-|-\n",
    "x|o\n",
    "\n",
    "and training data 2 would look like this\n",
    "\n",
    "o|x\n",
    "-|-\n",
    "x|o\n",
    "\n",
    "The top two boxes are Gothenburg/Sydney bottom two are Paris,  the right boxes are July and the left boxes are December.\n",
    "\n",
    "\n",
    "As we can see we can easily draw a line that separates the two classes in example 1 but not in example 2. This means that the perceptron can only classify example 1 and not example 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "## Implementing the SVC\n",
    "\n",
    "### The following table shows the accuracy achived with the different classifiers\n",
    "\n",
    "| Classifier | Accuracy |\n",
    "| --- | --- |\n",
    "| PegasosSVC | 0.8443 |\n",
    "| PegasosLREG | 0.8359 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our implemetation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for lab 4\n",
    "import numpy as np\n",
    "from aml_perceptron import LinearClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The _PegasosSVC_ was implemented with by translating the pseudocode from the document _'Clarification of the pseudocode in the Pegasos paper'_ with the help of the clarification in said document. The algorithm was run with several different combinations of parameters before settling on the following:\n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| lambda_reg | 0.01 |\n",
    "|n_iter | 100 000 |\n",
    "\n",
    "### The code cell below shows the implementation of the PegasosSVC algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PegasosSVC(LinearClassifier):\n",
    "    \"\"\"\n",
    "    Implementation of the Pegasos algorithm for SVCs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_reg=0.1, n_iter=1000000):\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        # Preprocess the data\n",
    "        self.find_classes(Y)\n",
    "        Y_encoded = self.encode_outputs(Y)\n",
    "\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = X.toarray()\n",
    "\n",
    "        # Initialize the weights\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.lambda_reg = 1/n_features\n",
    "\n",
    "        # Pegasos algorithm implemented\n",
    "        # like the peudocode in the paper\n",
    "        for t in range(1, self.n_iter):\n",
    "            rand = np.random.randint(0, len(X))\n",
    "            x, y = X[rand], Y_encoded[rand]\n",
    "\n",
    "            n = 1/(self.lambda_reg*t)\n",
    "\n",
    "            score = x.dot(self.w)\n",
    "\n",
    "            if y*score <= 1:\n",
    "                self.w = (1 - n*self.lambda_reg) * self.w + n*y*x\n",
    "            else:\n",
    "                self.w = (1 - n*self.lambda_reg) * self.w\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following two code cells is doc_classification.py that was provided by the course. It was modified to fit the _PegasosSVC_ algorithm instead of perceptron as it was orignally. We split it up and simplified it to make it easier to understand and to make it easier to implement the _PegasosSVC_ and _PegasosLREG_ algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads the corpus, returns a list of documents, and a list\n",
    "# of their corresponding polarity labels.\n",
    "\n",
    "\n",
    "def read_data(corpus_file):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, y, _, x = line.split(maxsplit=3)\n",
    "            X.append(x.strip())\n",
    "            Y.append(y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When we run the code cell below it will print the **accuracy** of the _PegasosSVC_ algorithm.\n",
    "\n",
    "## Accuracy: 0.8443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 17.93 sec.\n",
      "Accuracy: 0.8443.\n"
     ]
    }
   ],
   "source": [
    "# Read all the documents.\n",
    "X, Y = read_data(\n",
    "    'data/all_sentiment_shuffled.txt')\n",
    "# Split into training and test parts.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                random_state=69)\n",
    "\n",
    "# Set up the preprocessing steps and the classifier.\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    SelectKBest(k=1000),\n",
    "    Normalizer(),\n",
    "    # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "    PegasosSVC()\n",
    ")\n",
    "\n",
    "# Train the classifier.\n",
    "t0 = time.time()\n",
    "pipeline.fit(Xtrain, Ytrain)\n",
    "t1 = time.time()\n",
    "print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "# Evaluate on the test set.\n",
    "Yguess = pipeline.predict(Xtest)\n",
    "print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PegsosLREG is the \n",
    "\n",
    "| Parameter | Value |\n",
    "| --- | --- |\n",
    "| lambda_reg | 0.1 |\n",
    "|n_iter | 100 000 |\n",
    "\n",
    "### The code cell below shows the implementation of the PegasosLREG algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PegasosLREG(LinearClassifier):\n",
    "    \"\"\"\n",
    "    Implementation of the Pegasos algorithm for logistic regression.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lambda_reg=0.1, n_iter=100000):\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "\n",
    "        # Preprocess the data\n",
    "        self.find_classes(Y)\n",
    "        Y_encoded = self.encode_outputs(Y)\n",
    "\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = X.toarray()\n",
    "\n",
    "        # Initialize the weights\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.lambda_reg = 1/n_features\n",
    "\n",
    "        # Pegasos algorithm implemented with logistic regression\n",
    "        for t in range(1, self.n_iter):\n",
    "            rand = np.random.randint(0, len(X))\n",
    "            x, y = X[rand], Y_encoded[rand]\n",
    "\n",
    "            n = 1/(self.lambda_reg*t)\n",
    "\n",
    "            score = x.dot(self.w)\n",
    "            gradient = -y * x * (1 - 1/(1 + np.exp(-y * score)))\n",
    "\n",
    "            self.w = (1 - n * self.lambda_reg) * self.w - n * gradient\n",
    "            self.w *= min(1, 1 / (np.sqrt(self.lambda_reg)\n",
    "                          * np.linalg.norm(self.w)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing values for lambda and n_iter for linear regression (we conlclude that most values for n_iter over 50 000 giuve the highest accuracies and that lambda values between 0.1 and 0.0001 does not make a huge difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 3.72 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8317.\n",
      "lambda_reg:  0.1 n_iter:  65536\n",
      "Training time: 5.76 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8317.\n",
      "lambda_reg:  0.1 n_iter:  131072\n",
      "Training time: 11.75 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8330.\n",
      "lambda_reg:  0.1 n_iter:  262144\n",
      "Training time: 3.41 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8317.\n",
      "lambda_reg:  0.01 n_iter:  65536\n",
      "Training time: 5.57 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8246.\n",
      "lambda_reg:  0.01 n_iter:  131072\n",
      "Training time: 10.52 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8242.\n",
      "lambda_reg:  0.01 n_iter:  262144\n",
      "Training time: 3.52 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8284.\n",
      "lambda_reg:  0.001 n_iter:  65536\n",
      "Training time: 5.88 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8292.\n",
      "lambda_reg:  0.001 n_iter:  131072\n",
      "Training time: 10.21 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8326.\n",
      "lambda_reg:  0.001 n_iter:  262144\n",
      "Training time: 3.43 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8309.\n",
      "lambda_reg:  0.0001 n_iter:  65536\n",
      "Training time: 5.50 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8300.\n",
      "lambda_reg:  0.0001 n_iter:  131072\n",
      "Training time: 10.21 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8338.\n",
      "lambda_reg:  0.0001 n_iter:  262144\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0.1, 0.01, 0.001, 0.0001]:\n",
    "    for exp in range(13,20):\n",
    "        n_iter = 2**exp\n",
    "        X, Y = read_data(\n",
    "        'data/all_sentiment_shuffled.txt')\n",
    "        # Split into training and test parts.\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                        random_state=69)\n",
    "\n",
    "        # Set up the preprocessing steps and the classifier.\n",
    "        pipeline = make_pipeline(\n",
    "            TfidfVectorizer(),\n",
    "            SelectKBest(k=1000),\n",
    "            Normalizer(),\n",
    "            # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "            PegasosLREG(lambda_reg=lambda_reg, n_iter=n_iter)\n",
    "        )\n",
    "\n",
    "        # Train the classifier.\n",
    "        t0 = time.time()\n",
    "        pipeline.fit(Xtrain, Ytrain)\n",
    "        t1 = time.time()\n",
    "        print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "        # Evaluate on the test set.\n",
    "        Yguess = pipeline.predict(Xtest)\n",
    "        print('---------------------')\n",
    "        print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n",
    "        print(\"lambda_reg: \", lambda_reg, \"n_iter: \", n_iter)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing values for linearSVC we get the same conclusion that a value of n_iter over 50 000 is prefered and all lambda_reg values between 0.1 and 0.0001 work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 2.07 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8443.\n",
      "lambda_reg:  0.1 n_iter:  32768\n",
      "Training time: 2.25 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8389.\n",
      "lambda_reg:  0.1 n_iter:  65536\n",
      "Training time: 3.14 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8393.\n",
      "lambda_reg:  0.1 n_iter:  131072\n",
      "Training time: 5.11 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8431.\n",
      "lambda_reg:  0.1 n_iter:  262144\n",
      "Training time: 9.54 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8443.\n",
      "lambda_reg:  0.1 n_iter:  524288\n",
      "Training time: 1.77 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8372.\n",
      "lambda_reg:  0.01 n_iter:  32768\n",
      "Training time: 2.16 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8393.\n",
      "lambda_reg:  0.01 n_iter:  65536\n",
      "Training time: 3.26 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8405.\n",
      "lambda_reg:  0.01 n_iter:  131072\n",
      "Training time: 5.95 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8397.\n",
      "lambda_reg:  0.01 n_iter:  262144\n",
      "Training time: 8.97 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8435.\n",
      "lambda_reg:  0.01 n_iter:  524288\n",
      "Training time: 1.68 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8401.\n",
      "lambda_reg:  0.001 n_iter:  32768\n",
      "Training time: 2.20 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8389.\n",
      "lambda_reg:  0.001 n_iter:  65536\n",
      "Training time: 4.22 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8393.\n",
      "lambda_reg:  0.001 n_iter:  131072\n",
      "Training time: 7.97 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8460.\n",
      "lambda_reg:  0.001 n_iter:  262144\n",
      "Training time: 10.02 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8439.\n",
      "lambda_reg:  0.001 n_iter:  524288\n",
      "Training time: 1.66 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8347.\n",
      "lambda_reg:  0.0001 n_iter:  32768\n",
      "Training time: 2.24 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8410.\n",
      "lambda_reg:  0.0001 n_iter:  65536\n",
      "Training time: 3.17 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8426.\n",
      "lambda_reg:  0.0001 n_iter:  131072\n",
      "Training time: 5.47 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8435.\n",
      "lambda_reg:  0.0001 n_iter:  262144\n",
      "Training time: 9.05 sec.\n",
      "---------------------\n",
      "Accuracy: 0.8447.\n",
      "lambda_reg:  0.0001 n_iter:  524288\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0.1, 0.01, 0.001, 0.0001]:\n",
    "    for exp in range(13,20):\n",
    "        n_iter = 2**exp\n",
    "        X, Y = read_data(\n",
    "        'data/all_sentiment_shuffled.txt')\n",
    "        # Split into training and test parts.\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                        random_state=69)\n",
    "\n",
    "        # Set up the preprocessing steps and the classifier.\n",
    "        pipeline = make_pipeline(\n",
    "            TfidfVectorizer(),\n",
    "            SelectKBest(k=1000),\n",
    "            Normalizer(),\n",
    "            # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "            PegasosSVC(lambda_reg=lambda_reg, n_iter=n_iter)\n",
    "        )\n",
    "\n",
    "        # Train the classifier.\n",
    "        t0 = time.time()\n",
    "        pipeline.fit(Xtrain, Ytrain)\n",
    "        t1 = time.time()\n",
    "        print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "        # Evaluate on the test set.\n",
    "        Yguess = pipeline.predict(Xtest)\n",
    "        print('---------------------')\n",
    "        print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n",
    "        print(\"lambda_reg: \", lambda_reg, \"n_iter: \", n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 5.11 sec.\n",
      "Accuracy: 0.8359.\n"
     ]
    }
   ],
   "source": [
    "# Read all the documents.\n",
    "X, Y = read_data(\n",
    "    'data/all_sentiment_shuffled.txt')\n",
    "# Split into training and test parts.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2,\n",
    "                                                random_state=69)\n",
    "\n",
    "# Set up the preprocessing steps and the classifier.\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(),\n",
    "    SelectKBest(k=1000),\n",
    "    Normalizer(),\n",
    "    # NB that this is our Perceptron, not sklearn.linear_model.Perceptron\n",
    "    PegasosLREG(n_iter=100000, lambda_reg=0.01)\n",
    ")\n",
    "\n",
    "# Train the classifier.\n",
    "t0 = time.time()\n",
    "pipeline.fit(Xtrain, Ytrain)\n",
    "t1 = time.time()\n",
    "print('Training time: {:.2f} sec.'.format(t1-t0))\n",
    "# Evaluate on the test set.\n",
    "Yguess = pipeline.predict(Xtest)\n",
    "print('Accuracy: {:.4f}.'.format(accuracy_score(Ytest, Yguess)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
