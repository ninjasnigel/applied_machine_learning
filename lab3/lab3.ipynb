{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text\n",
    "from keras import utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that decides what symbols to keep\n",
    "symb_keep = [\" \", \"!\", \"?\", \".\", \",\"] + list(string.ascii_letters)\n",
    "str_fix = lambda str: \"\".join([char.lower() if char in symb_keep else \"\" for char in str]).replace(\"‚Äô\", \"'\")\n",
    "\n",
    "# Load training data\n",
    "with open('PA3_train.tsv', encoding=\"utf-8\") as f:\n",
    "    Y_train, X_train = [list(a) for a in list(zip(*[(int(line[0]), str_fix(line[4:])) for line in [line for line in f.readlines() if len(line) > 4] if (line.strip() and line[0] == line[2])]))]\n",
    "    \n",
    "with open('PA3_train_final.tsv', encoding=\"utf-8\") as f:\n",
    "    Y_train_extra, X_train_extra = zip(*[(int(line[0]), str_fix(line[6:])) for line in [line for line in f.readlines() if len(line) > 6] if (line.strip and line[0] == line[2] and line[2] == line[4])])\n",
    "\n",
    "Y_train += Y_train_extra\n",
    "X_train += X_train_extra\n",
    "\n",
    "# Load test data\n",
    "with open('PA3_test.tsv', encoding=\"utf-8\") as f:\n",
    "    Y_test, X_test = zip(*[(int(line[0]), str_fix(line[2:])) for line in f.readlines()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and save deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "777/777 [==============================] - 53s 66ms/step - loss: 0.1267 - accuracy: 0.9536 - val_loss: 0.0455 - val_accuracy: 0.9891\n",
      "Epoch 2/5\n",
      " 61/777 [=>............................] - ETA: 45s - loss: 0.0323 - accuracy: 0.9887"
     ]
    }
   ],
   "source": [
    "# Prepare model\n",
    "\n",
    "# Set input size\n",
    "max_words = 5000\n",
    "\n",
    "# Tokenize layers\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(X_train) # only fit on train\n",
    "\n",
    "# Convert text to matrix\n",
    "X_train = tokenize.texts_to_matrix(X_train)\n",
    "X_test = tokenize.texts_to_matrix(X_test)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "Y_train = encoder.transform(Y_train)\n",
    "Y_test = encoder.transform(Y_test)\n",
    "\n",
    "num_classes = np.max(Y_train) + 1\n",
    "Y_train = utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "# Set batch size and amount of epochs\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# Compire and save model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.save('resturant_classifier.h5')\n",
    "              \n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,verbose=1, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
