{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "658      normal\n",
      "1734     normal\n",
      "1226     normal\n",
      "1808     normal\n",
      "825     suspect\n",
      "         ...   \n",
      "1033     normal\n",
      "1731     normal\n",
      "763      normal\n",
      "835      normal\n",
      "1653     normal\n",
      "Name: NSP, Length: 2126, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# Read the CSV file.\n",
    "data = pd.read_csv('data.csv', skiprows=1)\n",
    "\n",
    "# Select the relevant numerical columns.\n",
    "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
    "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
    "                 'Median', 'Variance', 'Tendency', 'NSP']\n",
    "data = data[selected_cols].dropna()\n",
    "\n",
    "# Shuffle the dataset.\n",
    "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "X = data_shuffled.drop('NSP', axis=1)\n",
    "\n",
    "# Map the diagnosis code to a human-readable label.\n",
    "def to_label(y):\n",
    "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
    "\n",
    "\n",
    "Y = data_shuffled['NSP'].apply(to_label)\n",
    "print(Y)\n",
    "\n",
    "# Partition the data into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>DP</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>...</th>\n",
       "      <th>Width</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>134.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB   AC   FM   UC   DL   DS   DP  ASTV  MSTV  ALTV  ...  Width  \\\n",
       "658   130.0  1.0  0.0  3.0  0.0  0.0  0.0  24.0   1.2  12.0  ...   35.0   \n",
       "1734  134.0  9.0  1.0  8.0  5.0  0.0  0.0  59.0   1.2   0.0  ...  109.0   \n",
       "1226  125.0  1.0  0.0  4.0  0.0  0.0  0.0  43.0   0.7  31.0  ...   21.0   \n",
       "1808  143.0  0.0  0.0  1.0  0.0  0.0  0.0  69.0   0.3   6.0  ...   27.0   \n",
       "825   152.0  0.0  0.0  4.0  0.0  0.0  0.0  62.0   0.4  59.0  ...   25.0   \n",
       "\n",
       "        Min    Max  Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  \n",
       "658   120.0  155.0   1.0     0.0  134.0  133.0   135.0       1.0       0.0  \n",
       "1734   80.0  189.0   6.0     0.0  150.0  146.0   150.0      33.0       0.0  \n",
       "1226  120.0  141.0   0.0     0.0  131.0  130.0   132.0       1.0       0.0  \n",
       "1808  132.0  159.0   1.0     0.0  145.0  144.0   146.0       1.0       0.0  \n",
       "825   136.0  161.0   0.0     0.0  159.0  156.0   158.0       1.0       1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf0 = DecisionTreeClassifier(random_state=0)\n",
    "clf1 = RandomForestClassifier(random_state=0)\n",
    "clf2 = GradientBoostingClassifier(random_state=0)\n",
    "clf3 = LogisticRegression(random_state=0)\n",
    "clf4 = Perceptron(random_state=0)\n",
    "clf5 = LinearSVC(random_state=0)\n",
    "clf6 = MLPClassifier(random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validate all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/david/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/david/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/david/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/david/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/david/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/david/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/david/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/david/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/david/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = []\n",
    "\n",
    "scores.append((cross_val_score(clf0, Xtrain, Ytrain), \"DecisionTreeClassifier\"))\n",
    "scores.append((cross_val_score(clf1, Xtrain, Ytrain), \"RandomForestClassifier\"))\n",
    "scores.append((cross_val_score(clf2, Xtrain, Ytrain), \"GradientBoostingClassifier\"))\n",
    "scores.append((cross_val_score(clf3, Xtrain, Ytrain), \"LogisticRegression\"))\n",
    "scores.append((cross_val_score(clf4, Xtrain, Ytrain), \"Perceptron\"))\n",
    "scores.append((cross_val_score(clf5, Xtrain, Ytrain), \"LinearSVC\"))\n",
    "scores.append((cross_val_score(clf6, Xtrain, Ytrain), \"MLPClassifier\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the highest performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9513725490196079, 'GradientBoostingClassifier'), (0.9380392156862746, 'RandomForestClassifier'), (0.916078431372549, 'DecisionTreeClassifier'), (0.8784313725490197, 'MLPClassifier'), (0.8698039215686275, 'LogisticRegression'), (0.8109803921568627, 'LinearSVC'), (0.7576470588235293, 'Perceptron')]\n"
     ]
    }
   ],
   "source": [
    "max = [(np.sum(score[0])/5,score[1]) for score in scores]\n",
    "\n",
    "print(sorted(max, key=lambda x: x[0], reverse=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Final evaluation\n",
    "\n",
    "When you have found a classifier that gives a high accuracy in the cross-validation evaluation, train it on the whole training set and evaluate it on the held-out test set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf0, clf1, and clf2 are the highest performing from the data-set above so we train them on the entire data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 DecisionTreeClassifier(random_state=0)\n",
      "1.0 RandomForestClassifier(random_state=0)\n",
      "0.9905992949471211 GradientBoostingClassifier(random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifiers = [clf0, clf1, clf2]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X, Y)\n",
    "    Yguess = clf.predict(Xtest)\n",
    "    print(accuracy_score(Ytest, Yguess), clf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Decision trees for classification\n",
    "\n",
    "We could not get the code to run in this notebook (?) but out code runs in the included Lecture 1.ipynb\n",
    "\n",
    "Below is a copy of what is written there:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUR CODE FOR TASK 2\n",
    "\n",
    "We create a list containing depth values from 1 to 16, and from there we pick and print the one with the highest accuracy.\n",
    "\n",
    "It seems like 12 is the best value for this scenario, and after a depth of 12 the acurracy wstarts to fall of for this data-set.\n",
    "\n",
    "We also print and show a desicion tree with depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mnormal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msuspect\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpathologic\u001b[39m\u001b[39m'\u001b[39m][(\u001b[39mint\u001b[39m(y))]\n\u001b[1;32m     20\u001b[0m YNEW \u001b[39m=\u001b[39m data_shuffled[\u001b[39m'\u001b[39m\u001b[39mNSP\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(to_label)\n\u001b[0;32m---> 21\u001b[0m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfit(XNEW, YNEW)\n\u001b[1;32m     23\u001b[0m best_classifier \u001b[39m=\u001b[39m _, \u001b[39m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m max_depth \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m16\u001b[39m):\n",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m, in \u001b[0;36mTreeClassifier.fit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnknown criterion: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, Y)\n\u001b[1;32m     21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mset\u001b[39m(Y))\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mDecisionTree.fit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     23\u001b[0m Y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Y)        \n\u001b[0;32m---> 24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_tree(X, Y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_depth)\n",
      "Cell \u001b[0;32mIn[10], line 66\u001b[0m, in \u001b[0;36mDecisionTree.make_tree\u001b[0;34m(self, X, Y, max_depth)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m# Select the \"most useful\" feature and split threshold. To rank the \"usefulness\" of features,\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39m# we use one of the classification or regression criteria.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m# For each feature, we call best_split (defined in a subclass). We then maximize over the features.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m _, best_feature, best_threshold \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_split(X, Y, feature) \u001b[39mfor\u001b[39;49;00m feature \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(n_features))\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m best_feature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m DecisionTreeLeaf(default_value)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "cls = TreeClassifier(max_depth=3)\n",
    "\n",
    "data = pd.read_csv('data.csv', skiprows=1)\n",
    "# Select the relevant numerical columns.\n",
    "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
    "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
    "                 'Median', 'Variance', 'Tendency', 'NSP']\n",
    "data = data[selected_cols].dropna()\n",
    "\n",
    "# Shuffle the dataset.\n",
    "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "XNEW = data_shuffled.drop('NSP', axis=1)\n",
    "\n",
    "# Map the diagnosis code to a human-readable label.\n",
    "def to_label(y):\n",
    "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
    "\n",
    "YNEW = data_shuffled['NSP'].apply(to_label)\n",
    "cls.fit(XNEW, YNEW)\n",
    "\n",
    "best_classifier = _, 0\n",
    "for max_depth in range(1, 16):\n",
    "    print('Classifying tree at', max_depth+1, 'of', 16, end=\"\\r\")\n",
    "    clfTree = TreeClassifier(max_depth)\n",
    "    clfTree.fit(XNEW, YNEW)\n",
    "    score = cross_val_score(clfTree, XNEW, YNEW, cv=5, scoring='accuracy').mean()\n",
    "    if score > best_classifier[1]:\n",
    "        best_classifier = clfTree, score\n",
    "\n",
    "print(best_classifier)\n",
    "cls.draw_tree()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: A regression example: predicting apartment prices\n",
    "\n",
    "Here\n",
    "Links to an external site. is another dataset. This dataset was created by Sberbank and contains some statistics from the Russian real estate market. Here\n",
    "\n",
    "Links to an external site. is the Kaggle page where you can find the original data.\n",
    "\n",
    "Since we will just be able to handle numerical features and not symbolic ones, we'll need with a simplified version of the dataset. So we'll just select 9 of the columns in the dataset. The goal is to predict the price of an apartment, given numerical information such as the number of rooms, the size of the apartment in square meters, the floor, etc. Our approach will be similar to what we did in the classification example: load the data, find a suitable model using cross-validation over the training set, and finally evaluate on the held-out test data.\n",
    "\n",
    "The following code snippet will carry out the basic reading and preprocessing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file using Pandas.\n",
    "alldata = pd.read_csv('sberbank.csv')\n",
    "\n",
    "# Convert the timestamp string to an integer representing the year.\n",
    "def get_year(timestamp):\n",
    "    return int(timestamp[:4])\n",
    "alldata['year'] = alldata.timestamp.apply(get_year)\n",
    "\n",
    "# Select the 9 input columns and the output column.\n",
    "selected_columns = ['price_doc', 'year', 'full_sq', 'life_sq', 'floor', 'num_room', 'kitch_sq', 'full_all']\n",
    "alldata = alldata[selected_columns]\n",
    "alldata = alldata.dropna()\n",
    "\n",
    "# Shuffle.\n",
    "alldata_shuffled = alldata.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Separate the input and output columns.\n",
    "X = alldata_shuffled.drop('price_doc', axis=1)\n",
    "# For the output, we'll use the log of the sales price.\n",
    "Y = alldata_shuffled['price_doc'].apply(np.log)\n",
    "\n",
    "# Split into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer to qustion 3\n",
    "\n",
    "In the code, four different regression models are used: RandomForestRegressor, Ridge, Lasso, and GradientBoostingRegressor. The hyperparameters of each model are set, and the models are trained on the training dataset (Xtrain, Ytrain) using cross-validation. The negative mean squared error is then calculated for each model on the test dataset.\n",
    "\n",
    "To compare the performance of the models, you can look at the value of the negative mean squared error for each model. The model with the negative mean squared error that is closest to zero is considered to be the best model. \n",
    "\n",
    "It is important to note that the performance of a regression model can depend on the specific dataset being used, and the choice of evaluation metric may also affect the comparison of models. The number of combinations are also endlesss so there is no way of knowing what the optimal model is. We only know that we don't have the worst modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2659229822429888\n",
      "-0.3013978423217977\n",
      "-0.30104708463292107\n",
      "-0.2929452077385661\n",
      "-0.31737303376625764Score:  -0.31737303376625764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#Test a some regression models\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=0)\n",
    "print((cross_validate(regr, Xtrain, Ytrain,\n",
    "      scoring='neg_mean_squared_error').get('test_score')).mean())\n",
    "\n",
    "regr = Ridge(alpha=1, random_state=0, solver='auto', max_iter=100, tol=1e-1)\n",
    "print((cross_validate(regr, Xtrain, Ytrain,\n",
    "          scoring='neg_mean_squared_error').get('test_score')).mean())\n",
    "\n",
    "regr = Lasso(alpha=1, random_state=0, max_iter=100, tol=1e-1)\n",
    "print((cross_validate(regr, Xtrain, Ytrain,\n",
    "          scoring='neg_mean_squared_error').get('test_score')).mean())\n",
    "\n",
    "regr = GradientBoostingRegressor(n_estimators=100, max_depth=10, random_state=0)\n",
    "print((cross_validate(regr, Xtrain, Ytrain, scoring = 'neg_mean_squared_error').get('test_score')).mean())\n",
    "\n",
    "#random forest regressor seems promising, let's test it with different parameters\n",
    "#Test a set of combinations for random forest regressor for a set of variables that we think will be important\n",
    "\n",
    "best_score = -5\n",
    "n_estimators = 0\n",
    "max_depth = 0\n",
    "\n",
    "for n_estimators in [5, 10, 100]:\n",
    "    for max_depth in [1, 10, 100]:\n",
    "        regressor = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=0)\n",
    "        score = ((cross_validate(regr, Xtrain, Ytrain, scoring='neg_mean_squared_error').get('test_score'))).mean()\n",
    "        print('Iteration: ', n_estimators, max_depth, 'Score: ', score, end='\\r')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            n_estimators = n_estimators\n",
    "            max_depth = max_depth\n",
    "            regr = regressor\n",
    "\n",
    "\n",
    "print((cross_validate(regr, Xtrain, Ytrain,\n",
    "      scoring='neg_mean_squared_error').get('test_score')).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29907312957355675"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "  \n",
    "#Use the best combination of variables to train the model\n",
    "regr = RandomForestRegressor(n_estimators = n_estimators , max_depth = max_depth, random_state=0)\n",
    "regr.fit(Xtrain, Ytrain)\n",
    "\n",
    "mean_squared_error(Ytest, regr.predict(Xtest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
