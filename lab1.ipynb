{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# Read the CSV file.\n",
    "data = pd.read_csv('data.csv', skiprows=1)\n",
    "\n",
    "# Select the relevant numerical columns.\n",
    "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
    "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
    "                 'Median', 'Variance', 'Tendency', 'NSP']\n",
    "data = data[selected_cols].dropna()\n",
    "\n",
    "# Shuffle the dataset.\n",
    "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "X = data_shuffled.drop('NSP', axis=1)\n",
    "\n",
    "# Map the diagnosis code to a human-readable label.\n",
    "def to_label(y):\n",
    "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
    "\n",
    "Y = data_shuffled['NSP'].apply(to_label)\n",
    "\n",
    "# Partition the data into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Training the baseline classifier\n",
    "\n",
    "We can now start to investigate different classifiers.\n",
    "\n",
    "The DummyClassifier\n",
    "Links to an external site. is a simple classifier that does not make use of the features: it just returns the most common label in the training set, in this case Spondylolisthesis. The purpose of using such a stupid classifier is as a baseline: a simple classifier that we can try before we move on to more complex classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how well our simple classifier works, we carry out a cross-validation Links to an external site. over the training set and compute the classification accuracy on each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_score\n\u001b[0;32m----> 3\u001b[0m cross_val_score(clf, Xtrain, Ytrain)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(clf, Xtrain, Ytrain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Trying out some different classifiers\n",
    "\n",
    "Replace the DummyClassifier with some more meaningful classifier and run the cross-validation again. Try out a few classifiers and see how much you can improve the cross-validation accuracy. Remember, the accuracy is defined as the proportion of correctly classified instances, and we want this value to be high.\n",
    "\n",
    "Here are some possible options:\n",
    "\n",
    "Tree-based classifiers:\n",
    "\n",
    "    sklearn.tree.DecisionTreeClassifier \n",
    "\n",
    "Links to an external site.\n",
    "sklearn.ensemble.RandomForestClassifier\n",
    "Links to an external site.\n",
    "sklearn.ensemble.GradientBoostingClassifier\n",
    "\n",
    "    Links to an external site.\n",
    "\n",
    "Linear classifiers:\n",
    "\n",
    "    sklearn.linear_model.Perceptron \n",
    "\n",
    "Links to an external site.\n",
    "sklearn.linear_model.LogisticRegression\n",
    "Links to an external site.\n",
    "sklearn.svm.LinearSVC\n",
    "\n",
    "    Links to an external site.\n",
    "\n",
    "Neural network classifier (will take longer time to train):\n",
    "\n",
    "    sklearn.neural_network.MLPClassifier \n",
    "\n",
    "    Links to an external site.\n",
    "\n",
    "You may also try to tune the hyperparameters of the various classifiers to improve the performance. For instance, the decision tree classifier has a parameter that sets the maximum depth, and in the neural network classifier you can control the number of layers and the number of neurons in each layer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Final evaluation\n",
    "\n",
    "When you have found a classifier that gives a high accuracy in the cross-validation evaluation, train it on the whole training set and evaluate it on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m----> 3\u001b[0m clf\u001b[39m.\u001b[39mfit(Xtrain, Ytrain)\n\u001b[1;32m      4\u001b[0m Yguess \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(Xtest)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(accuracy_score(Ytest, Yguess))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "clf.fit(Xtrain, Ytrain)\n",
    "Yguess = clf.predict(Xtest)\n",
    "print(accuracy_score(Ytest, Yguess))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the report. In your submitted report, include a list of three classifiers you tried in Step 3 and their accuracies, add a description of the classifier you selected in Step 4 and report its accuracy. (At this point, we are of course not asking you to describe internal workings of various machine learning models that we will cover in detail at later points during the course, but you are of course free to read about them if you're interested.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
